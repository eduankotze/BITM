{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding GPT-2 (\"next token prediction\")\n",
    "\n",
    "**2025/03/26**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <mark>**Download na: C:\\Users\\kotzeje\\.cache\\huggingface\\hub\\models--gpt2**</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://huggingface.co/openai-community/gpt2\n",
    "    * This is the smallest version of GPT-2, with 124M parameters.\n",
    "* https://huggingface.co/openai-community/gpt2-large\n",
    "    * GPT-2 Large is the 774M parameter version of GPT-2\n",
    "* https://huggingface.co/openai-community/gpt2-xl\n",
    "    * GPT-2 XL is the 1.5B parameter version of GPT-2\n",
    " \n",
    "****\n",
    "\n",
    " * https://huggingface.co/EleutherAI/gpt-neo-2.7B\n",
    "    * **GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n",
      "4.46.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt/gpt-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "# You can use \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\" for larger models\n",
    "model_name = \"gpt2\"  \n",
    "\n",
    "model_name = r\"D:\\Data\\huggingface\\models\\openai-community\\openai-gpt2-small\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, `model.eval()` is a method that switches a neural network model (like GPT-2 in your code) to evaluation mode. This doesn't change the model's weights or structure but `adjusts how certain layers behave during inference (prediction) compared to training`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: D:\\Data\\huggingface\\models\\openai-community\\openai-gpt2-small\n",
      "Number of parameters: 124,439,808\n"
     ]
    }
   ],
   "source": [
    "# Count the number of parameters: 124M\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tokens(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)  # Move input to GPU/CPU\n",
    "\n",
    "    # Show input tokenization\n",
    "    input_token_ids = input_ids[0].tolist()  # Convert tensor to list of token IDs\n",
    "    input_tokens = [tokenizer.decode([token_id]) for token_id in input_token_ids]\n",
    "\n",
    "    print(f\"Input string: '{input_text}'\")\n",
    "    print(\"Tokenized into IDs:\", input_token_ids)\n",
    "    print(\"Decoded tokens:\", input_tokens)\n",
    "    print()\n",
    "\n",
    "    # Generate predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        predictions = outputs.logits\n",
    "    \n",
    "    # Get the last token's predictions (logits for next token)\n",
    "    last_token_logits = predictions[0, -1, :]\n",
    "    \n",
    "    # Get top 10 predicted tokens\n",
    "    top_k = 10\n",
    "    top_token_ids = torch.topk(last_token_logits, top_k).indices\n",
    "    top_token_probs = torch.softmax(last_token_logits, dim=-1)[top_token_ids]\n",
    "    \n",
    "    # Decode tokens and prepare results\n",
    "    results = []\n",
    "    for token_id, prob in zip(top_token_ids, top_token_probs):\n",
    "        token = tokenizer.decode(token_id)\n",
    "        results.append((token_id.item(), token, prob.item()))\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Top {top_k} predicted token IDs following '{input_text}':\")\n",
    "    for i, (token_id, token, prob) in enumerate(results, 1):\n",
    "        print(f\"{i}. Token ID: {token_id:<5} Token: '{token:<10}' Probability: {prob:.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: 'one, two, three,'\n",
      "Tokenized into IDs: [505, 11, 734, 11, 1115, 11]\n",
      "Decoded tokens: ['one', ',', ' two', ',', ' three', ',']\n",
      "\n",
      "Top 10 predicted token IDs following 'one, two, three,':\n",
      "1. Token ID: 1440  Token: ' four     ' Probability: 0.6087\n",
      "2. Token ID: 1936  Token: ' five     ' Probability: 0.0768\n",
      "3. Token ID: 290   Token: ' and      ' Probability: 0.0528\n",
      "4. Token ID: 2237  Token: ' six      ' Probability: 0.0349\n",
      "5. Token ID: 393   Token: ' or       ' Probability: 0.0273\n",
      "6. Token ID: 1115  Token: ' three    ' Probability: 0.0267\n",
      "7. Token ID: 734   Token: ' two      ' Probability: 0.0123\n",
      "8. Token ID: 3624  Token: ' eight    ' Probability: 0.0093\n",
      "9. Token ID: 530   Token: ' one      ' Probability: 0.0088\n",
      "10. Token ID: 257   Token: ' a        ' Probability: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\OpenAILangChain\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:545: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# Input sequence\n",
    "input_text = \"one, two, three,\"\n",
    "show_tokens(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in how \"one\", \" two\", and \" three\" are tokenized—with spaces before \" two\" and \" three\" but not \"one\"—is a result of how `GPT-2’s Byte-Pair Encoding (BPE)` tokenizer works. \" two\" <> \"two\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'one' → Token ID: 505 → Decoded: 'one'\n",
      "Word: 'two' → Token ID: 11545 → Decoded: 'two'\n",
      "Word: ' two' → Token ID: 734 → Decoded: ' two'\n",
      "Word: 'two,' → Token ID: 11545 → Decoded: 'two'\n"
     ]
    }
   ],
   "source": [
    "# Test individual words\n",
    "for word in [\"one\", \"two\", \" two\", \"two,\"]:\n",
    "    token_ids = tokenizer.encode(word)\n",
    "    decoded = tokenizer.decode(token_ids[0])\n",
    "    print(f\"Word: '{word}' → Token ID: {token_ids[0]} → Decoded: '{decoded}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tokenizer.encode(\"one\") → [505] (no space)\n",
    "* tokenizer.encode(\"two\") → [11545] (no space, a different token ID)\n",
    "* tokenizer.encode(\" two\") → [734] (with space)\n",
    "* tokenizer.encode(\"two\") → [11545] (with comma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc  # Garbage collection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean up memory\n",
    "def cleanup_torch():\n",
    "    # Clear GPU cache if using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()  # Collect inter-process communication memory\n",
    "    \n",
    "    # Force garbage collection for CPU RAM\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly delete large objects\n",
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory cleanup completed.\n"
     ]
    }
   ],
   "source": [
    "# Clean up memory\n",
    "cleanup_torch()\n",
    "\n",
    "print(\"\\nMemory cleanup completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt-large\n",
    "\n",
    "https://huggingface.co/openai-community/gpt2-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = r\"D:\\Data\\huggingface\\models\\openai-community\\openai-gpt2-large\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: D:\\Data\\huggingface\\models\\openai-community\\openai-gpt2-large\n",
      "Number of parameters: 774,030,080\n"
     ]
    }
   ],
   "source": [
    "# Count the number of parameters: 774M\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: 'one, two, three,'\n",
      "Tokenized into IDs: [505, 11, 734, 11, 1115, 11]\n",
      "Decoded tokens: ['one', ',', ' two', ',', ' three', ',']\n",
      "\n",
      "Top 10 predicted token IDs following 'one, two, three,':\n",
      "1. Token ID: 1440  Token: ' four     ' Probability: 0.5132\n",
      "2. Token ID: 393   Token: ' or       ' Probability: 0.0905\n",
      "3. Token ID: 290   Token: ' and      ' Probability: 0.0767\n",
      "4. Token ID: 3503  Token: ' etc      ' Probability: 0.0442\n",
      "5. Token ID: 1936  Token: ' five     ' Probability: 0.0170\n",
      "6. Token ID: 530   Token: ' one      ' Probability: 0.0074\n",
      "7. Token ID: 772   Token: ' even     ' Probability: 0.0070\n",
      "8. Token ID: 257   Token: ' a        ' Probability: 0.0057\n",
      "9. Token ID: 734   Token: ' two      ' Probability: 0.0054\n",
      "10. Token ID: 2237  Token: ' six      ' Probability: 0.0053\n"
     ]
    }
   ],
   "source": [
    "# Input sequence\n",
    "input_text = \"one, two, three,\"\n",
    "show_tokens(input_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Top 10 predicted token IDs following 'one, two, three,':\n",
    "1. Token ID: 1440  Token: ' four     ' Probability: 0.6087\n",
    "2. Token ID: 1936  Token: ' five     ' Probability: 0.0768\n",
    "3. Token ID: 290   Token: ' and      ' Probability: 0.0528\n",
    "4. Token ID: 2237  Token: ' six      ' Probability: 0.0349\n",
    "5. Token ID: 393   Token: ' or       ' Probability: 0.0273\n",
    "6. Token ID: 1115  Token: ' three    ' Probability: 0.0267\n",
    "7. Token ID: 734   Token: ' two      ' Probability: 0.0123\n",
    "8. Token ID: 3624  Token: ' eight    ' Probability: 0.0093\n",
    "9. Token ID: 530   Token: ' one      ' Probability: 0.0088\n",
    "10. Token ID: 257   Token: ' a        ' Probability: 0.0083"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did language models go from predicting the next word token to answering long, complex prompts? \n",
    "\n",
    "Read: https://www.reddit.com/r/learnmachinelearning/comments/17gd8mi/how_did_language_models_go_from_predicting_the/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would argue the exact moment instructGPT (https://arxiv.org/abs/2203.02155) was introduced....\n",
    "\n",
    " This is the backbone of GPT 3.5 (aka ChatGPT). It's a multi-stage process, but the gist of it this:\n",
    "\n",
    "    * the raw next-token predictor (GPT 3) outputs multiple answers for each question in a database\n",
    "\n",
    "    * for each question, humans rank the answers\n",
    "\n",
    "    * GPT 3 is fine-tuned to prefer the higher-ranked answers.\n",
    "\n",
    "This technique is called RLHF (Reinforcement Learning from Human Feedback).\n",
    "\n",
    "I also think this is the main differentiator between transformers which did <mark>\"just next-token prediction\" (eg the GPT 1,2,3)</mark> and the <mark>\"conversational models\" (eg. GPT 3.5, 4, Claude)</mark> you can see now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer  # Note: GPT-Neo uses GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly delete large objects\n",
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory cleanup completed.\n"
     ]
    }
   ],
   "source": [
    "# Clean up memory\n",
    "cleanup_torch()\n",
    "print(\"\\nMemory cleanup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get GPU memory usage\n",
    "def get_gpu_memory():\n",
    "    return torch.cuda.memory_allocated() / 1024**2, torch.cuda.max_memory_allocated() / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU memory used: 8.75 MB, Peak: 3074.67 MB\n"
     ]
    }
   ],
   "source": [
    "initial_used, initial_peak = get_gpu_memory()\n",
    "print(f\"Initial GPU memory used: {initial_used:.2f} MB, Peak: {initial_peak:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads a 11GB file, be patient...\n",
    "\n",
    "#model_name = r\"D:\\Data\\huggingface\\models\\EleutherAI\\gpt-neo-2.7B\"\n",
    "model_name = r\"C:\\models\\EleutherAI\\gpt-neo-2.7B\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used after loading model: 10378.70 MB, Peak: 10378.70 MB\n"
     ]
    }
   ],
   "source": [
    "# GPU Memory usage after loading model: 10GB!!!\n",
    "model_loaded_used, model_loaded_peak = get_gpu_memory()\n",
    "print(f\"GPU memory used after loading model: {model_loaded_used:.2f} MB, Peak: {model_loaded_peak:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: C:\\models\\EleutherAI\\gpt-neo-2.7B\n",
      "Number of parameters: 2,651,307,520\n"
     ]
    }
   ],
   "source": [
    "# Count the number of parameters: 2.6B\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: 'one, two, three, five,'\n",
      "Tokenized into IDs: [505, 11, 734, 11, 1115, 11, 1936, 11]\n",
      "Decoded tokens: ['one', ',', ' two', ',', ' three', ',', ' five', ',']\n",
      "\n",
      "Top 10 predicted token IDs following 'one, two, three, five,':\n",
      "1. Token ID: 3598  Token: ' seven    ' Probability: 0.3162\n",
      "2. Token ID: 2237  Token: ' six      ' Probability: 0.2400\n",
      "3. Token ID: 290   Token: ' and      ' Probability: 0.1036\n",
      "4. Token ID: 3478  Token: ' ten      ' Probability: 0.0566\n",
      "5. Token ID: 3624  Token: ' eight    ' Probability: 0.0471\n",
      "6. Token ID: 393   Token: ' or       ' Probability: 0.0396\n",
      "7. Token ID: 530   Token: ' one      ' Probability: 0.0277\n",
      "8. Token ID: 3503  Token: ' etc      ' Probability: 0.0229\n",
      "9. Token ID: 5193  Token: ' nine     ' Probability: 0.0172\n",
      "10. Token ID: 1440  Token: ' four     ' Probability: 0.0118\n"
     ]
    }
   ],
   "source": [
    "# Input sequence\n",
    "input_text = \"one, two, three, five,\"\n",
    "show_tokens(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text Instead of Just Predicting Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 'one, two, three, four, five, six, seven, eight, nine, ten,'\n"
     ]
    }
   ],
   "source": [
    "# After loading model and tokenizing input\n",
    "model.to(\"cuda\")\n",
    "input_ids = tokenizer.encode(\"one, two, three,\", return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate text\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=20,  # Total tokens (input + generated)\n",
    "        do_sample=True,  # Random sampling for variety\n",
    "        top_k=50,        # Consider top 50 tokens\n",
    "        temperature=0.1  # Control randomness (0.1 very strict)\n",
    "    )\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(f\"Generated text: '{generated_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Token Probability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.to(\"cuda\")\n",
    "input_ids = tokenizer.encode(\"one, two, three,\", return_tensors=\"pt\").to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    predictions = model(input_ids).logits[0, -1, :]\n",
    "probs = torch.softmax(predictions, dim=-1)\n",
    "top_k = 15\n",
    "top_vals, top_ids = torch.topk(probs, top_k)\n",
    "\n",
    "# Plot\n",
    "plt.bar(range(top_k), top_vals.cpu().numpy())\n",
    "plt.xticks(range(top_k), [tokenizer.decode([tid]) for tid in top_ids], rotation=90)\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(f\"Top {top_k} Token Probabilities\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Inference Speed (across batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 1: 0.2472 seconds (4.05 sequences/sec)\n",
      "Batch size 4: 0.0542 seconds (73.85 sequences/sec)\n",
      "Batch size 8: 0.0290 seconds (275.84 sequences/sec)\n",
      "Batch size 16: 0.0311 seconds (513.82 sequences/sec)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model.to(\"cuda\")\n",
    "batch_sizes = [1, 4, 8, 16]\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    input_ids = tokenizer.encode(\"one, two, three,\", return_tensors=\"pt\").repeat(bs, 1).to(\"cuda\")\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        model(input_ids)\n",
    "        \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Batch size {bs}: {elapsed:.4f} seconds ({bs/elapsed:.2f} sequences/sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Attention Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What This Does\n",
    "\n",
    "    Sliding Window:\n",
    "        Takes 3-token chunks: \"one, two\", \"two, three\", \"three,\".\n",
    "        For each window, it runs the model to get attention weights and the top predicted token.\n",
    "    Attention Extraction:\n",
    "        outputs.attentions[-1] grabs the last layer’s attention (most meaningful for final predictions).\n",
    "        [0, -1, :, -1] gets the attention scores for the last token in the window predicting the next one.\n",
    "    Comparison:\n",
    "        Also shows attention for the full sequence (\"one, two, three,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 505,   11,  734,   11, 1115,   11]], device='cuda:0')\n",
      "['one', ',', ' two', ',', ' three', ',']\n",
      "***************************************************************************\n",
      "Attention tensor shape: torch.Size([1, 20, 6, 6])\n",
      "\n",
      "Full sequence: one, two, three,\n",
      "Attention weights:\n",
      "  'one       ': 0.6749\n",
      "  ',         ': 0.0093\n",
      "  ' two      ': 0.0133\n",
      "  ',         ': 0.0240\n",
      "  ' three    ': 0.0187\n",
      "  ',         ': 0.2599\n",
      "Sum of attention weights: 1.0000\n",
      "last_token_attention.sum() should be close to 1, confirming proper normalization.\n"
     ]
    }
   ],
   "source": [
    "# Input sequence\n",
    "input_text = \"one, two, three,\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "tokens = [tokenizer.decode([tid]) for tid in input_ids[0]]\n",
    "print(input_ids)\n",
    "print(tokens)\n",
    "print(75*'*')\n",
    "\n",
    "# Full sequence attention\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, output_attentions=True)\n",
    "    attentions = outputs.attentions[-1]  # Last layer's attention\n",
    "    print(f\"Attention tensor shape: {attentions.shape}\")  # Debug shape\n",
    "\n",
    "    # Average across all attention heads for the last token's attention\n",
    "    last_token_attention = attentions[0, :, -1, :].mean(dim=0)  # [batch, heads, query, key] -> mean over heads\n",
    "\n",
    "# Print full sequence attention\n",
    "print(f\"\\nFull sequence: {input_text}\")\n",
    "print(\"Attention weights:\")\n",
    "for token, attn in zip(tokens, last_token_attention):\n",
    "    print(f\"  '{token:<10}': {attn.item():.4f}\")\n",
    "print(f\"Sum of attention weights: {last_token_attention.sum().item():.4f}\")\n",
    "print(\"last_token_attention.sum() should be close to 1, confirming proper normalization.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attention tensor shape: torch.Size([1, 20, 6, 6])\n",
    "\n",
    "That means:\n",
    "\n",
    "        1 batch\n",
    "\n",
    "        20 attention heads\n",
    "\n",
    "        6 tokens in the input\n",
    "\n",
    "        Each head assigns weights over the 6 tokens (self-attention)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the full sequence \"one, two, three,\", it shows how much attention the model gives to each previous token when processing the last token (in this case, the final comma).\n",
    "\n",
    "Highest attention: \"one\" (0.6749) and the last comma (0.2599).\n",
    "\n",
    "This suggests the model is strongly attending back to the start of the list, possibly because it's learning the pattern of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window 1: one ,  two\n",
      "Attention weights:\n",
      "  'one       ': 0.6900\n",
      "  ',         ': 0.0042\n",
      "  ' two      ': 0.3058\n",
      "Predicted next token: ','\n",
      "Sum of attention weights: 1.0000\n",
      "last_token_attention.sum() should be close to 1, confirming proper normalization.\n",
      "\n",
      "Window 2: ,  two ,\n",
      "Attention weights:\n",
      "  ',         ': 0.6890\n",
      "  ' two      ': 0.0468\n",
      "  ',         ': 0.2642\n",
      "Predicted next token: ' three'\n",
      "Sum of attention weights: 1.0000\n",
      "last_token_attention.sum() should be close to 1, confirming proper normalization.\n",
      "\n",
      "Window 3:  two ,  three\n",
      "Attention weights:\n",
      "  ' two      ': 0.6926\n",
      "  ',         ': 0.0126\n",
      "  ' three    ': 0.2948\n",
      "Predicted next token: ','\n",
      "Sum of attention weights: 1.0000\n",
      "last_token_attention.sum() should be close to 1, confirming proper normalization.\n",
      "\n",
      "Window 4: ,  three ,\n",
      "Attention weights:\n",
      "  ',         ': 0.6947\n",
      "  ' three    ': 0.0492\n",
      "  ',         ': 0.2562\n",
      "Predicted next token: ' four'\n",
      "Sum of attention weights: 1.0000\n",
      "last_token_attention.sum() should be close to 1, confirming proper normalization.\n"
     ]
    }
   ],
   "source": [
    "# Slide a 3-token window and analyze attention\n",
    "window_size = 3\n",
    "for i in range(len(input_ids[0]) - window_size + 1):\n",
    "    window_ids = input_ids[:, i:i + window_size]\n",
    "    window_tokens = tokens[i:i + window_size]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(window_ids, output_attentions=True)\n",
    "        attentions = outputs.attentions[-1]\n",
    "        last_token_attention = attentions[0, :, -1, :].mean(dim=0)\n",
    "    \n",
    "    top_id = torch.argmax(outputs.logits[0, -1, :]).item()\n",
    "    top_token = tokenizer.decode(top_id)\n",
    "    \n",
    "    print(f\"\\nWindow {i + 1}: {' '.join(window_tokens)}\")\n",
    "    print(\"Attention weights:\")\n",
    "    for token, attn in zip(window_tokens, last_token_attention):\n",
    "        print(f\"  '{token:<10}': {attn.item():.4f}\")\n",
    "    print(f\"Predicted next token: '{top_token}'\")\n",
    "    print(f\"Sum of attention weights: {last_token_attention.sum().item():.4f}\")\n",
    "    print(\"last_token_attention.sum() should be close to 1, confirming proper normalization.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sliding Attention Windows -> Each \"Window\" shows a chunk of the input the model sees when predicting the next token.\n",
    "\n",
    "Window 1: one , two\n",
    "\n",
    "    The model pays most attention to \"one\" (0.6900) and \"two\" (0.3058).\n",
    "    It predicts the next token is \",\", which is correct for a list.\n",
    "\n",
    "Window 2: , two ,\n",
    "\n",
    "    The commas dominate attention here (0.6899 and 0.2642), with \"two\" getting very little (0.0468).\n",
    "    The next token is predicted as \"three\", again continuing the list pattern.\n",
    "\n",
    "Window 3: two , three\n",
    "\n",
    "    The model mostly attends to \"two\" (0.6926) and \"three\" (0.2948).\n",
    "    It predicts another comma, keeping with the list rhythm.\n",
    "\n",
    "Window 4: , three ,\n",
    "\n",
    "    Similar to Window 2, commas get the highest weights.\n",
    "    The predicted next token is \"four\", which follows logically in a list."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### TAKE AWAY FROM THIS: ####\n",
    "\n",
    "Self-attention helps the model look back at relevant tokens. In a list like \"one, two, three,\", the model learns to alternate between words and commas and uses attention to track the structure of the sequence. The highest weights often fall on the items directly relevant for predicting the next item in the pattern."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "~Eof"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAILangChain",
   "language": "python",
   "name": "openailangchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
